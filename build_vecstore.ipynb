{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyM5xGCWwkOh1tDlUfVf70YG",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/wang1091/SmartEarningCall/blob/main/build_vecstore.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LtunTgH2rl2D"
      },
      "outputs": [],
      "source": [
        "!pip install boto3\n",
        "!pip install langchain-community\n",
        "!pip install langchain-huggingface\n",
        "import os\n",
        "import boto3\n",
        "import hashlib\n",
        "from langchain_community.document_loaders import TextLoader\n",
        "from langchain.text_splitter import CharacterTextSplitter\n",
        "from langchain_huggingface import HuggingFaceEmbeddings\n",
        "from langchain_community.vectorstores import FAISS\n",
        "from get_config import load_config  # ‚ú® Áõ¥Êé•ÂºïÂÖ• config\n",
        "\n",
        "def calculate_md5(file_path):\n",
        "    \"\"\"Calculate the MD5 checksum of a local file.\"\"\"\n",
        "    hasher = hashlib.md5()\n",
        "    with open(file_path, 'rb') as f:\n",
        "        buf = f.read()\n",
        "        hasher.update(buf)\n",
        "    return hasher.hexdigest()\n",
        "\n",
        "def list_local_files(local_folder):\n",
        "    \"\"\"List all .txt files in a local folder and calculate their MD5 checksums.\"\"\"\n",
        "    local_files = {}\n",
        "    if not os.path.exists(local_folder):\n",
        "        return local_files  # Return empty if folder does not exist yet\n",
        "    for filename in os.listdir(local_folder):\n",
        "        if filename.endswith('.txt'):\n",
        "            full_path = os.path.join(local_folder, filename)\n",
        "            local_files[filename] = calculate_md5(full_path)\n",
        "    return local_files\n",
        "\n",
        "def list_s3_files(bucket_name, prefix, aws_access_key, aws_secret_key):\n",
        "    \"\"\"List all .txt files in an S3 bucket and get their ETag (MD5 checksum).\"\"\"\n",
        "    s3 = boto3.client('s3',\n",
        "                      aws_access_key_id=aws_access_key,\n",
        "                      aws_secret_access_key=aws_secret_key)\n",
        "    paginator = s3.get_paginator('list_objects_v2')\n",
        "    s3_files = {}\n",
        "    for page in paginator.paginate(Bucket=bucket_name, Prefix=prefix):\n",
        "        for obj in page.get('Contents', []):\n",
        "            key = obj['Key']\n",
        "            if key.endswith('.txt') and not key.endswith('/'):\n",
        "                filename = os.path.basename(key)\n",
        "                s3_files[filename] = obj['ETag'].strip('\"')\n",
        "    return s3_files\n",
        "\n",
        "def download_s3_files(bucket_name, prefix, local_folder, aws_access_key, aws_secret_key):\n",
        "    \"\"\"Download all .txt files from an S3 bucket to a local folder.\"\"\"\n",
        "    os.makedirs(local_folder, exist_ok=True)\n",
        "    s3 = boto3.client('s3',\n",
        "                      aws_access_key_id=aws_access_key,\n",
        "                      aws_secret_access_key=aws_secret_key)\n",
        "    paginator = s3.get_paginator('list_objects_v2')\n",
        "    for page in paginator.paginate(Bucket=bucket_name, Prefix=prefix):\n",
        "        for obj in page.get('Contents', []):\n",
        "            key = obj['Key']\n",
        "            if key.endswith('.txt') and not key.endswith('/'):\n",
        "                filename = os.path.basename(key)\n",
        "                local_path = os.path.join(local_folder, filename)\n",
        "                s3.download_file(bucket_name, key, local_path)\n",
        "                print(f\"‚úÖ Downloaded {filename}\")\n",
        "\n",
        "def build_vectorstore(local_folder, save_path):\n",
        "    \"\"\"Build a FAISS vectorstore from .txt files in a local folder and save it.\"\"\"\n",
        "    all_docs = []\n",
        "    for filename in os.listdir(local_folder):\n",
        "        if filename.endswith('transcript.txt'):\n",
        "            loader = TextLoader(os.path.join(local_folder, filename), encoding='utf-8')\n",
        "            docs = loader.load()\n",
        "            all_docs.extend(docs)\n",
        "\n",
        "    splitter = CharacterTextSplitter(separator=\"\\n\\n\", chunk_size=2000, chunk_overlap=100)\n",
        "    chunks = splitter.split_documents(all_docs)\n",
        "\n",
        "    embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/multi-qa-MiniLM-L6-cos-v1\")\n",
        "    vectorstore = FAISS.from_documents(chunks, embeddings)\n",
        "    vectorstore.save_local(save_path)\n",
        "    print(f\"‚úÖ Vectorstore built and saved to {save_path}\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # === Load Configuration ===\n",
        "    config = load_config()\n",
        "\n",
        "    bucket_name = config.get('bucket_name')\n",
        "    prefix = config.get('prefix', 'earning_call_transcript/')\n",
        "    local_folder = config.get('local_folder', 'data')\n",
        "    save_path = config.get('save_path', 'faiss_index')\n",
        "    aws_access_key = config.get('aws_access_key_id')\n",
        "    aws_secret_key = config.get('aws_secret_access_key')\n",
        "\n",
        "    # === Execution ===\n",
        "    print(\"üîç Checking for updates...\")\n",
        "    local_files = list_local_files(local_folder)\n",
        "    s3_files = list_s3_files(bucket_name, prefix, aws_access_key, aws_secret_key)\n",
        "\n",
        "    if local_files != s3_files:\n",
        "        print(\"Detected changes. Downloading files and rebuilding vectorstore...\")\n",
        "        download_s3_files(bucket_name, prefix, local_folder, aws_access_key, aws_secret_key)\n",
        "        build_vectorstore(local_folder, save_path)\n",
        "    else:\n",
        "        print(\"No changes detected. Skipping download and build.\")\n"
      ]
    }
  ]
}